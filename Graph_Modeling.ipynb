{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kmgN5oJGLhLT",
        "riUQd_gG9PRY",
        "GTBimSEf9jkW",
        "Rzo66rzzAdME",
        "UZo0DJkiAhpb",
        "MjptK0FbKAxd",
        "Do6jyX4VOIMT",
        "dpqPM4awUBAA",
        "h6dlbbZlkTcy",
        "3T3u_MuyCuDO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmgN5oJGLhLT"
      },
      "source": [
        "# Eternal Module Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FjoSWK_TT4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de139912-c2ab-4825-f943-a30082716c3e"
      },
      "source": [
        "! pip install openbiolink"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openbiolink\n",
            "  Downloading openbiolink-0.1.4-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from openbiolink) (1.12.0+cu113)\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.7/dist-packages (from openbiolink) (4.64.0)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from openbiolink) (1.3.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from openbiolink) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openbiolink) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->openbiolink) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->openbiolink) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.4->openbiolink) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->openbiolink) (4.1.1)\n",
            "Installing collected packages: openbiolink\n",
            "Successfully installed openbiolink-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "    return version.split('+')[0]\n",
        "\n",
        "def format_cuda_version(version):\n",
        "    return 'cu' + version.replace('.', '')\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "mc1ptwP5xHwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c18231d-634a-41c3-8e3d-e0dbfd7de155"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.0+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_sparse-0.6.14-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.0+cu113.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 2.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.0+cu113.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (709 kB)\n",
            "\u001b[K     |████████████████████████████████| 709 kB 2.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=a0c1b3ed8883752f5e35da45bf27fae4bd3584df9193d97b578946b2cf3632d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.21.6)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch_geometric) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module Imports"
      ],
      "metadata": {
        "id": "riUQd_gG9PRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openbiolink.obl2021 import OBL2021Dataset, OBL2021Evaluator\n",
        "# import torch\n",
        "from torch.nn import Module,\\\n",
        "                     ModuleList,\\\n",
        "                     Embedding,\\\n",
        "                     BatchNorm1d,\\\n",
        "                     ReLU,\\\n",
        "                     Linear,\\\n",
        "                     BCEWithLogitsLoss,\\\n",
        "                     MarginRankingLoss,\\\n",
        "                     CrossEntropyLoss,\\\n",
        "                     Dropout\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric as PyG\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn.conv import RGCNConv\n",
        "# from torch_geometric.utils import to_networkx\n",
        "# import networkx as nx\n",
        "# import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from typing import NoReturn\n",
        "import typing\n",
        "# import time\n",
        "from enum import Enum\n",
        "# from datetime import datetime\n",
        "# from collections import defaultdict"
      ],
      "metadata": {
        "id": "SYfjWfsh9UE5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading + Preprocessing"
      ],
      "metadata": {
        "id": "GTBimSEf9jkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = OBL2021Dataset()\n",
        "evaluator = OBL2021Evaluator()\n",
        "kg = torch.cat((dataset.training, dataset.validation, dataset.testing), dim=0)\n",
        "entities = dataset.candidates\n",
        "train_set = dataset.training\n",
        "dev_set = dataset.validation\n",
        "test_set = dataset.testing"
      ],
      "metadata": {
        "id": "0GiwxvQK9t-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0192e68f-2b12-40fa-aa31-26f360fe3f81"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset not found, downloading to /content/obl2021 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "KGID_HQ_DIR.zip: 45.2MB [00:14, 3.29MB/s]                            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PcUcz0z-Kaj9",
        "outputId": "551a67e3-3622-4bfc-b581-e81d98929c0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Triples:     \\n     Train 4192002\\n     Valid 186301\\n     Test  180964\\n# Relations:   28\\n# Entities:    180992\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.num_relations"
      ],
      "metadata": {
        "id": "vkwcwyX3DLQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4140c9-5303-44bb-a4e2-51535ca8bfe2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "Rzo66rzzAdME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DistMult"
      ],
      "metadata": {
        "id": "UZo0DJkiAhpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistMultModel(Module):\n",
        "  def __init__(self, num_entities: int, num_relations: int, embedding_size: int) -> NoReturn:\n",
        "    super(DistMultModel, self).__init__()\n",
        "    self.num_entities = num_entities\n",
        "    self.num_relations = num_relations\n",
        "    self.embedding_size = embedding_size\n",
        "    self.entity_encoder = Embedding(self.num_entities, self.embedding_size)\n",
        "    self.relation_encoder = Embedding(self.num_relations, self.embedding_size)\n",
        "\n",
        "  def _encode_triplets(self, triplets: torch.Tensor) -> tuple:\n",
        "    h_heads = self.entity_encoder(triplets[:, 0])\n",
        "    h_tails = self.entity_encoder(triplets[:, 2])\n",
        "    h_relations = self.relation_encoder(triplets[:, 1])\n",
        "    return h_heads, h_relations, h_tails\n",
        "\n",
        "  def forward(self, data_triplets: tuple((torch.Tensor, torch.Tensor))) -> tuple:\n",
        "    p_triplets, n_triplets = data_triplets\n",
        "    p_heads, p_relations, p_tails = self._encode_triplets(p_triplets)\n",
        "    n_heads, n_relations, n_tails = self._encode_triplets(n_triplets)\n",
        "\n",
        "    p_scores = (p_heads * p_relations * p_tails).sum(-1)\n",
        "    n_scores = (n_heads * n_relations * n_tails).sum(-1)\n",
        "\n",
        "    return p_scores, n_scores"
      ],
      "metadata": {
        "id": "g8UwcJ7lAkCj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RESCAL"
      ],
      "metadata": {
        "id": "MjptK0FbKAxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RESCALModel(Module):\n",
        "  def __init__(self, num_entities: int, num_relations: int, embedding_size: int) -> NoReturn:\n",
        "    super(RESCALModel, self).__init__()\n",
        "    self.num_entities = num_entities\n",
        "    self.num_relations = num_relations\n",
        "    self.embedding_size = embedding_size\n",
        "    self.entity_encoder = Embedding(self.num_entities, self.embedding_size)\n",
        "    self.relation_encoder = Embedding(self.num_relations, self.embedding_size * self.embedding_size)\n",
        "\n",
        "  def _encode_triplets(self, triplets: torch.Tensor) -> tuple:\n",
        "    h_heads = self.entity_encoder(triplets[:, 0])\n",
        "    h_tails = self.entity_encoder(triplets[:, 2])\n",
        "    h_relations = self.relation_encoder(triplets[:, 1]).reshape(-1, self.embedding_size, self.embedding_size)\n",
        "    return h_heads, h_relations, h_tails\n",
        "\n",
        "  def forward(self, data_triplets: tuple((torch.Tensor, torch.Tensor))) -> tuple:\n",
        "    p_triplets, n_triplets = data_triplets\n",
        "    p_heads, p_relations, p_tails = self._encode_triplets(p_triplets)\n",
        "    n_heads, n_relations, n_tails = self._encode_triplets(n_triplets)\n",
        "\n",
        "    n_scores = torch.matmul(\n",
        "        torch.matmul(n_heads.reshape(-1, 1, self.embedding_size), n_relations),\n",
        "        n_tails.reshape(-1, self.embedding_size, 1)\n",
        "    )\n",
        "\n",
        "    p_scores = torch.matmul(\n",
        "        torch.matmul(p_heads.reshape(-1, 1, self.embedding_size), p_relations),\n",
        "        p_tails.reshape(-1, self.embedding_size, 1)\n",
        "    )\n",
        "\n",
        "    return p_scores.reshape(-1), n_scores.reshape(-1)"
      ],
      "metadata": {
        "id": "XO4i3tLkKDDR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hinge Loss"
      ],
      "metadata": {
        "id": "Do6jyX4VOIMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HingeLoss(Module):\n",
        "  def __init__(self, margin):\n",
        "    super(HingeLoss, self).__init__()\n",
        "    self.margin = margin\n",
        "    self.loss_fn = MarginRankingLoss(self.margin)\n",
        "\n",
        "  def forward(self, p_scores: torch.Tensor, n_scores: torch.Tensor) -> torch.Tensor:\n",
        "    positive = p_scores.repeat(n_scores.shape)\n",
        "    negative = n_scores.repeat(p_scores.shape)\n",
        "\n",
        "    return self.loss_fn(positive, negative, torch.ones(n_scores.shape[0] * p_scores.shape[0]).to(positive.device))\n"
      ],
      "metadata": {
        "id": "v3eP3OgBOQbI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Neural Network"
      ],
      "metadata": {
        "id": "dpqPM4awUBAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(Module):\n",
        "  def __init__(self, num_entities: int, num_relations: int, embedding_dim: int, conv_dims: tuple, dropout, num_bases=None, num_blocks=None):\n",
        "    super(GNN, self).__init__()\n",
        "    self.num_entities = num_entities\n",
        "    self.num_relations = num_relations\n",
        "    self.embedding_dim = embedding_dim \n",
        "    self.conv_channels = [self.embedding_dim] + list(conv_dims)\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.shallow_embedding = Embedding(self.num_entities, self.embedding_dim)\n",
        "    self.relation_embedding = Embedding(self.num_relations, self.conv_channels[-1])\n",
        "    self.emb_bn = BatchNorm1d(self.embedding_dim)\n",
        "    self.conv = ModuleList([\n",
        "                RGCNConv(dim, self.conv_channels[index + 1], num_relations=self.num_relations, num_bases=num_bases, num_blocks=num_blocks)\n",
        "                for index, dim in enumerate(self.conv_channels[:-1])\n",
        "    ])\n",
        "    self.conv_bn = ModuleList([\n",
        "                        BatchNorm1d(dim)\n",
        "                        for dim in self.conv_channels[1:]\n",
        "    ])\n",
        "    self.activation = ReLU()\n",
        "    self.dropout = Dropout(p=self.dropout)\n",
        "\n",
        "  def _node_encoder(self, data: Data):\n",
        "    x = data.x\n",
        "    x = self.shallow_embedding(x)\n",
        "    x = self.emb_bn(x)\n",
        "    x = self.dropout(x)\n",
        "    for conv, conv_bn in zip(self.conv, self.conv_bn):\n",
        "      x = conv(x, data.edge_index, data.edge_type) \n",
        "      x = conv_bn(x)\n",
        "      x = self.activation(x)\n",
        "      x = self.dropout(x)\n",
        "    return x\n",
        "\n",
        "  def _triplet_decoder(self, encoded, triplets):\n",
        "    heads = encoded[triplets[:, 0]]\n",
        "    relations = self.relation_embedding(triplets[:, 1])\n",
        "    tails = encoded[triplets[:, 2]]\n",
        "    return (heads * relations * tails).sum(-1)\n",
        "  \n",
        "  def forward(self, data: Data):\n",
        "    nodes_h = self._node_encoder(data)\n",
        "    ## decoding part of the auto-encoder\n",
        "    p_scores = self._triplet_decoder(nodes_h, data.positive)\n",
        "    n_scores = self._triplet_decoder(nodes_h, data.negative)\n",
        "    return p_scores, n_scores\n"
      ],
      "metadata": {
        "id": "s8qaQzPVZMDp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Miner"
      ],
      "metadata": {
        "id": "pALKUNIP_lMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphMiner():\n",
        "  def __init__(self, dataset, device: str, cache_size: int=None, replacement_size: int=None) -> NoReturn:\n",
        "    self.device = device\n",
        "    self.dataset = dataset\n",
        "    self.training = self.dataset.training.to(self.device)\n",
        "    self.validation = self.dataset.validation.to(self.device)\n",
        "    self.testing = self.dataset.testing.to(self.device)\n",
        "    self.candidates = self.dataset.candidates.to(self.device)\n",
        "    if cache_size and replacement_size:\n",
        "      self.cache_size = cache_size\n",
        "      self.replacement_size = replacement_size\n",
        "      self.head_cache = (torch.rand(dataset.num_relations, entities.shape[0], cache_size) * entities.shape[0] - 1).round().long().to(self.device)\n",
        "      self.tail_cache = (torch.rand(entities.shape[0], dataset.num_relations, cache_size) * entities.shape[0] - 1).round().long().to(self.device)\n",
        "\n",
        "    self.num_entities = self.dataset.num_entities\n",
        "    self.num_relations = self.dataset.num_relations\n",
        "\n",
        "  def pyg_data(self, index, batch_size, negative_sampler):\n",
        "    indcs = torch.ones_like(self.training[:, 0], dtype=torch.bool)\n",
        "    not_include = torch.arange(index, index + batch_size, device=self.device)\n",
        "    indcs[not_include] = False\n",
        "\n",
        "    edge_index = self.training[indcs][:, (0, 2)].t().contiguous()\n",
        "    edge_type = self.training[indcs][:, 1].t().contiguous()\n",
        "    positive = self.training[index: index + batch_size, :]\n",
        "    negative = negative_sampler(positive)\n",
        "\n",
        "    return Data(\n",
        "        x=self.candidates,\n",
        "        edge_index=edge_index,\n",
        "        edge_type=edge_type,\n",
        "        positive=positive,\n",
        "        negative=negative\n",
        "    )\n",
        "\n",
        "  def uniform_negative_sample(self, batch):\n",
        "    batch_size = batch.shape[0]\n",
        "\n",
        "    head_relation = batch[:, (0, 1)].repeat(self.candidates.shape[0], 1)\n",
        "    relation_tail = batch[:, (1, 2)].repeat(self.candidates.shape[0], 1)\n",
        "\n",
        "    entities = self.candidates.reshape(-1, 1).repeat(batch_size, 1)\n",
        "    entities = torch.cat(torch.split(entities, self.candidates.shape[0]), -1).reshape(-1, 1)\n",
        "\n",
        "    corrupted_head_triplets = torch.cat(\n",
        "        (entities, relation_tail), \n",
        "        -1\n",
        "    )\n",
        "    corrupted_tail_triplets = torch.cat(\n",
        "        (head_relation, entities), \n",
        "        -1\n",
        "    )\n",
        "\n",
        "    negative_triplets = torch.cat((corrupted_head_triplets, corrupted_tail_triplets))\n",
        "    negative_triplets = torch.cat(torch.split(negative_triplets, batch_size), -1).reshape(batch_size, -1, 3)\n",
        "    indcs = (torch.rand(batch_size) * (self.candidates.shape[0] * 2 - 1)).round().long().to(self.device)\n",
        "    splits = torch.split(negative_triplets.reshape(-1, 3), self.candidates.shape[0] * 2)\n",
        "    splits = torch.stack(splits).reshape(-1, 3)\n",
        "\n",
        "    indcs += torch.arange(batch_size).to(self.device) * (2 * self.candidates.shape[0])\n",
        "    negative_samples = splits[indcs]\n",
        "    return negative_samples\n",
        "\n",
        "  def cache_negative_sample(self, batch):\n",
        "    batch_size = batch.shape[0]\n",
        "    heads = batch[:, 0]\n",
        "    tails = batch[:, 2]\n",
        "    relations = batch[:, 1]\n",
        "\n",
        "    candidate_heads = self.head_cache[relations, tails]\n",
        "    candidate_tails = self.tail_cache[heads, relations]\n",
        "\n",
        "    corrupt_head_indcs = (torch.rand(batch_size) * (self.cache_size - 1)).round().long().to(self.device) # 1 for each item in the batch?\n",
        "    corrupt_tail_indcs = (torch.rand(batch_size) * (self.cache_size - 1)).round().long().to(self.device) # 1 for each item in the batch?\n",
        "\n",
        "    corrupt_head_indcs += torch.arange(batch_size).to(self.device) * self.cache_size\n",
        "    corrupt_heads = candidate_heads.reshape(-1)[corrupt_head_indcs]\n",
        "\n",
        "    corrupt_tail_indcs += torch.arange(batch_size).to(self.device) * self.cache_size\n",
        "    corrupt_tails = candidate_tails.reshape(-1)[corrupt_tail_indcs]\n",
        "\n",
        "    corrupted_head_triplets = torch.cat((corrupt_heads.reshape(-1, 1), batch[:, (1, 2)]), -1)\n",
        "    corrupted_tail_triplets = torch.cat((batch[:, (0, 1)], corrupt_tails.reshape(-1, 1)), -1)\n",
        "    negative_triplets = torch.cat((corrupted_head_triplets, corrupted_tail_triplets), 0)\n",
        "\n",
        "    negative_triplets = torch.cat(torch.split(negative_triplets, batch_size), -1).reshape(batch_size, -1, 3)\n",
        "    indcs = torch.rand(batch_size).round().long().to(self.device)\n",
        "    splits = torch.split(negative_triplets.reshape(-1, 3), 1 * 2)\n",
        "\n",
        "    splits = torch.stack(splits).reshape(-1, 3)\n",
        "    indcs += torch.arange(batch_size).to(self.device) * (1 * 2)\n",
        "    negative_samples = splits[indcs]\n",
        "    # self.update_caches(batch, scoring_function)\n",
        "    return negative_samples\n",
        "\n",
        "  def _update_cache(self, batch, scoring_function, head_or_tail, **kwargs):\n",
        "    if kwargs.get('gnn'):\n",
        "      data = batch\n",
        "      batch = data.positive\n",
        "    batch_size = batch.shape[0]\n",
        "    heads = batch[:, 0]\n",
        "    tails = batch[:, 2]\n",
        "    relations = batch[:, 1]\n",
        "\n",
        "    replacement_candidates = (\n",
        "          torch.rand(\n",
        "              batch_size * self.replacement_size\n",
        "          ) * (self.candidates.shape[0] - 1)).round().long().reshape(batch_size, self.replacement_size).to(self.device)\n",
        "\n",
        "    if head_or_tail == 'head':\n",
        "      current_entities = self.head_cache[relations, tails]\n",
        "    elif head_or_tail == 'tail':\n",
        "      current_entities = self.tail_cache[heads, relations]\n",
        "\n",
        "    entities_pool = torch.cat((current_entities, replacement_candidates), -1)\n",
        "    if head_or_tail == 'head':\n",
        "      partial_triplets = batch[:, 1:]\n",
        "    elif head_or_tail == 'tail':\n",
        "      partial_triplets = batch[:, :2]\n",
        "    partial_triplets = partial_triplets.repeat(entities_pool.shape[1], 1)\n",
        "\n",
        "    partial_triplets = torch.cat(torch.split(partial_triplets, batch_size), -1).reshape(batch_size, -1, 2).reshape(-1, 2)\n",
        "\n",
        "    if head_or_tail == 'head':\n",
        "      pool = torch.cat((entities_pool.reshape(-1, 1), partial_triplets), -1)\n",
        "    elif head_or_tail == 'tail':\n",
        "      pool = torch.cat((partial_triplets, entities_pool.reshape(-1, 1)), -1)\n",
        "\n",
        "    dummy = torch.ones(1, 3).long().to(self.device)\n",
        "    input = (pool, dummy)\n",
        "    if kwargs.get('gnn'):\n",
        "      input = Data(\n",
        "              edge_index=data.edge_index,\n",
        "               edge_type=data.edge_type,\n",
        "               x=data.x,\n",
        "               positive=pool,\n",
        "               negative=dummy\n",
        "          )\n",
        "      \n",
        "    scoring_function.eval()\n",
        "    with torch.no_grad():\n",
        "      scores = scoring_function(input)[0]\n",
        "    \n",
        "    fitness = F.softmax(scores, 0)\n",
        "    split = torch.stack(torch.split(fitness, self.replacement_size + self.cache_size))\n",
        "\n",
        "    next_entities_indcs = split.multinomial(num_samples=self.cache_size)\n",
        "    if head_or_tail == 'head':\n",
        "      self.head_cache[relations, tails] = torch.take(entities_pool, next_entities_indcs)\n",
        "    elif head_or_tail == 'tail':\n",
        "      self.tail_cache[heads, relations] = torch.take(entities_pool, next_entities_indcs)\n",
        "\n",
        "  def update_caches(self, batch, scoring_function, **kwargs):\n",
        "    self._update_cache(batch, scoring_function, 'head', **kwargs)\n",
        "    self._update_cache(batch, scoring_function, 'tail', **kwargs)\n",
        "\n",
        "  def train(self, model: Module, data, optimizer: torch.optim, loss_fn, update_cache=False) -> tuple((torch.float, torch.Tensor, torch.Tensor)):\n",
        "    optimizer.zero_grad()\n",
        "    model.train()\n",
        "\n",
        "    positive, negative = model(data) # forward pass\n",
        "\n",
        "    loss = loss_fn(positive, negative) # margin ranking loss\n",
        "\n",
        "    loss.backward() # back propagation\n",
        "    optimizer.step() # parameter updates\n",
        "    if update_cache:\n",
        "      self.update_caches(data, model, gnn=True)\n",
        "    return loss.item()\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def _ranks(self, model, batch, **kwargs):\n",
        "    if kwargs.get('gnn'):\n",
        "      data = batch\n",
        "      batch = data.positive\n",
        "    batch_size = batch.shape[0]\n",
        "\n",
        "    head_relation = batch[:, (0, 1)].repeat(self.candidates.shape[0], 1)\n",
        "    relation_tail = batch[:, (1, 2)].repeat(self.candidates.shape[0], 1)\n",
        "\n",
        "    entities = self.candidates.reshape(-1, 1).repeat(batch_size, 1)\n",
        "    entities = torch.cat(torch.split(entities, self.candidates.shape[0]), -1).reshape(-1, 1)\n",
        "\n",
        "    corrupted_head_triplets = torch.cat(\n",
        "        (entities, relation_tail), \n",
        "        -1\n",
        "    )\n",
        "    corrupted_tail_triplets = torch.cat(\n",
        "        (head_relation, entities), \n",
        "        -1\n",
        "    )\n",
        "    corrupted_head_triplets = torch.cat(torch.split(corrupted_head_triplets, batch_size), -1).reshape(batch_size, -1, 3)\n",
        "    corrupted_tail_triplets = torch.cat(torch.split(corrupted_tail_triplets, batch_size), -1).reshape(batch_size, -1, 3)\n",
        "\n",
        "    heads = batch[:, 0]\n",
        "    tails = batch[:, 2]\n",
        "\n",
        "    dummy = torch.ones(1, 3).long().to(self.device)\n",
        "    input = corrupted_head_triplets.reshape(-1, 3)\n",
        "    if kwargs.get('gnn'):\n",
        "      input = Data(\n",
        "              edge_index=data.edge_index,\n",
        "               edge_type=data.edge_type,\n",
        "               x=data.x,\n",
        "               positive=input,\n",
        "               negative=dummy\n",
        "          )\n",
        "    else:\n",
        "      input = (input, dummy)\n",
        "    model.eval()\n",
        "    head_scores = model(\n",
        "        input\n",
        "    )[0].reshape(batch_size, -1)\n",
        "    head_ranks = (head_scores.gather(dim=1, index=heads.reshape(-1, 1)) <= head_scores).sum(-1) # Max Policy\n",
        "\n",
        "    input = corrupted_tail_triplets.reshape(-1, 3)\n",
        "    if kwargs.get('gnn'):\n",
        "      input = Data(\n",
        "              edge_index=data.edge_index,\n",
        "               edge_type=data.edge_type,\n",
        "               x=data.x,\n",
        "               positive=input,\n",
        "               negative=dummy\n",
        "          )\n",
        "    else:\n",
        "      input = (input, dummy)\n",
        "    tail_scores = model(\n",
        "        input\n",
        "    )[0].reshape(batch_size, -1)\n",
        "    tail_ranks = (tail_scores.gather(dim=1, index=tails.reshape(-1, 1)) <= tail_scores).sum(-1)\n",
        "\n",
        "    return head_ranks.reshape(-1), tail_ranks.reshape(-1)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def MRR(self, model, set_type, batch_size, use_tqdm=False, **kwargs):\n",
        "    if set_type == 'validation':\n",
        "      eval_set = self.validation\n",
        "      if kwargs.get('gnn'):\n",
        "        message = self.training\n",
        "    elif set_type == 'testing':\n",
        "      eval_set = self.testing\n",
        "      if kwargs.get('gnn'):\n",
        "        message = torch.cat((self.training, self.validation), 0)\n",
        "    else:\n",
        "      raise ValueError('Wrong data split specified.')\n",
        "    \n",
        "    sum = 0\n",
        "    size = 0\n",
        "\n",
        "    wrapper = tqdm if use_tqdm else (lambda z: z)\n",
        "    for batch in wrapper(torch.split(eval_set, batch_size)):\n",
        "      if kwargs.get('gnn'):\n",
        "        batch = Data(\n",
        "            edge_index=message[:, (0, 2)].t().contiguous(),\n",
        "            edge_type=message[:, 1].t().contiguous(),\n",
        "            x=self.candidates,\n",
        "            positive=batch\n",
        "        )\n",
        "      head_ranks, tail_ranks = self._ranks(model, batch, **kwargs)\n",
        "      sum += (1 / head_ranks).sum() + (1 / tail_ranks).sum()\n",
        "      size += head_ranks.shape[0] + tail_ranks.shape[0]\n",
        "    return sum / size\n",
        "\n",
        "    \n",
        "      "
      ],
      "metadata": {
        "id": "DfkRLMsc_nHG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "tNvebpdt_3KH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN"
      ],
      "metadata": {
        "id": "eMM5TBb_B7Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "gm = GraphMiner(dataset, device, 15, 15)\n",
        "gnn = GNN(gm.num_entities, gm.num_relations, 32, (32, 32, 32), 0.4, num_bases=5).to(device)\n",
        "optimizer = Adam(gnn.parameters())\n",
        "margin = 1\n",
        "criterion = HingeLoss(margin=margin)\n",
        "batch_size = 32\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "mS82r9UiprbE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  gm.training = gm.training[torch.randperm(gm.training.shape[0])]\n",
        "  epoch_loss = 0\n",
        "  for i in tqdm(range(0, gm.training.shape[0], batch_size)):\n",
        "    train_data = gm.pyg_data(i, batch_size, gm.cache_negative_sample)\n",
        "    batch_loss = gm.train(gnn, train_data, optimizer, criterion, True)\n",
        "    epoch_loss += batch_loss\n",
        "\n",
        "  print(f'Epoch {epoch}')\n",
        "  print(epoch_loss)  \n",
        "  if epoch % 10 == 1:\n",
        "    print(f'Validation MRR: {gm.MRR(gnn, \"validation\", 16, True, gnn=True)}')"
      ],
      "metadata": {
        "id": "Bv1m6nZEuipx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DistMult"
      ],
      "metadata": {
        "id": "lwbBkhMFCCV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gm = GraphMiner(dataset, 'cpu', 50, 50)\n",
        "dm = DistMultModel(gm.num_entities, gm.num_relations, 256)\n",
        "optimizer = Adam(dm.parameters(), weight_decay=3e-8)\n",
        "margin = 1\n",
        "criterion = HingeLoss(margin=margin)\n",
        "batch_size = 64\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "7ZKLZPeX5h6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = gm.training[:64]\n",
        "gm.cache_negative_sample(batch, dm)"
      ],
      "metadata": {
        "id": "wi0VeyhJVP43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  train_batches = torch.split(gm.training, batch_size)\n",
        "  epoch_loss = 0\n",
        "  for batch in tqdm(train_batches):\n",
        "    negative = gm.cache_negative_sample(batch, dm)\n",
        "    epoch_loss += gm.train(dm, (batch, negative), optimizer, criterion)\n",
        "  print(f'Epoch {epoch}')\n",
        "  print(epoch_loss)  \n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Validation MRR: {gm.MRR(dm, \"validation\", 64, True)}')"
      ],
      "metadata": {
        "id": "WLaXCuarUhdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RESCAL"
      ],
      "metadata": {
        "id": "RnGIUSfqCFF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rscl = RESCALModel(dataset.num_entities, gm.num_relations, 4).to('cuda')\n",
        "optm = Adam(rscl.parameters(), 1e-3)\n",
        "\n",
        "p = train_set[:100].to('cuda')\n",
        "n = gm.cache_negative_sample(p)\n",
        "# rscl((p, n))[0]"
      ],
      "metadata": {
        "id": "lRn0pwKSLAqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "  rscl.train()\n",
        "  p = train_set[:100].to('cuda')\n",
        "  n = gm.cache_negative_sample(p)\n",
        "  p_s, n_s = rscl((p, n))\n",
        "  loss = gm.margin_ranking_loss(p_s, n_s)\n",
        "  loss.backward()\n",
        "  optm.step()\n",
        "  print(loss.item())"
      ],
      "metadata": {
        "id": "nJqUJ4QeMQ5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gm."
      ],
      "metadata": {
        "id": "HGV4xn9TpZO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One by One Graph Miner"
      ],
      "metadata": {
        "id": "h6dlbbZlkTcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneGM():\n",
        "  def __init__(self, dataset, device: str, cache_size: int=None, replacement_size: int=None) -> NoReturn:\n",
        "    self.device = device\n",
        "    self.dataset = dataset\n",
        "    self.training = self.dataset.training.to(self.device)\n",
        "    self.validation = self.dataset.validation.to(self.device)\n",
        "    self.testing = self.dataset.testing.to(self.device)\n",
        "    self.candidates = self.dataset.candidates.to(self.device)\n",
        "    if cache_size and replacement_size:\n",
        "      self.cache_size = cache_size\n",
        "      self.replacement_size = replacement_size\n",
        "      self.head_cache = (torch.rand(dataset.num_relations, entities.shape[0], cache_size) * entities.shape[0] - 1).round().long().to(self.device)\n",
        "      self.tail_cache = (torch.rand(entities.shape[0], dataset.num_relations, cache_size) * entities.shape[0] - 1).round().long().to(self.device)\n",
        "\n",
        "    self.num_entities = self.dataset.num_entities\n",
        "    self.num_relations = self.dataset.num_relations\n",
        "\n",
        "  def pyg_data(self, index, batch_size, negative_sampler):\n",
        "    indcs = torch.ones_like(self.training[:, 0], dtype=torch.bool)\n",
        "    not_include = torch.arange(index, index + batch_size, device=self.device)\n",
        "    indcs[not_include] = False\n",
        "\n",
        "    edge_index = self.training[indcs][:, (0, 2)].t().contiguous()\n",
        "    edge_type = self.training[indcs][:, 1].t().contiguous()\n",
        "    positive = self.training[index: index + batch_size, :]\n",
        "    negative = negative_sampler(positive)\n",
        "\n",
        "    return Data(\n",
        "        x=self.candidates,\n",
        "        edge_index=edge_index,\n",
        "        edge_type=edge_type,\n",
        "        positive=positive,\n",
        "        negative=negative\n",
        "    )\n",
        "\n",
        "  def uniform_negative_sample(self, triplet, check=False):\n",
        "    okay = False\n",
        "    while not okay:\n",
        "      h, r, t = triplet\n",
        "      index = torch.round(torch.rand(1) * (self.candidates.shape[0] * 2)).long()\n",
        "      if index < self.candidates.shape[0]:\n",
        "        # corrupt head\n",
        "        negative_triplet = torch.tensor([self.candidates[index], r, t]).to(self.device).reshape(1, 3)\n",
        "      else:\n",
        "        # corrupt tail\n",
        "        index -= self.candidates.shape[0]\n",
        "        negative_triplet = torch.tensor([h, r, self.candidates[index]]).to(self.device).reshape(1, 3)\n",
        "      okay = (not check) or (not ((negative_triplet == self.training).sum(-1) == 3).sum())\n",
        "      return negative_triplet\n",
        "\n",
        "  def cache_negative_sample(self, triplet, check=False):\n",
        "    okay = False\n",
        "    h, r, t = triplet\n",
        "    index = torch.round(torch.rand(1) * self.cache_size - 1).long()\n",
        "    h_bar = self.head_cache[r][t][index]\n",
        "    index = torch.round(torch.rand(1) * self.cache_size - 1).long()\n",
        "    t_bar = self.tail_cache[h][r][index]\n",
        "    if torch.rand(1) < 0.5:\n",
        "      negative_triplet = torch.tensor([h_bar, r, t]).reshape(1, 3).to(self.device)\n",
        "    else:\n",
        "      negative_triplet = torch.tensor([h, r, t_bar]).reshape(1, 3).to(self.device)\n",
        "\n",
        "  def _update_cache(self, triplet, scoring_function, head_or_tail, **kwargs):\n",
        "    data = triplet\n",
        "    triplet = data.positive\n",
        "    h, r, t = triplet\n",
        "\n",
        "    new_candidates = torch.round(torch.rand(self.replacement_size) * (self.candidates.shape[0] - 1)).long()\n",
        "    if head_or_tail == 'head':\n",
        "      all_entities = torch.cat((self.head_cache[r][t], new_candidates)).reshape(-1, 1)\n",
        "    elif head_or_tail == 'tail':\n",
        "      all_entities = torch.cat((self.tail_cache[h][r], new_candidates)).reshape(-1, 1)\n",
        "    if head_or_tail == 'head':\n",
        "      partial = torch.tensor([r, t]).reshape(1, 2).repeat(self.cache_size + self.replacement_size, 1)\n",
        "      all_triplets = torch.cat((all_entities, partial), -1)\n",
        "    elif head_or_tail == 'tail':\n",
        "      partial = torch.tensor([h, r]).reshape(1, 2).repeat(cache_size + replacement_size, 1)\n",
        "      all_triplets = torch.cat((partial, all_entities), -1)\n",
        "    dummy = torch.ones(1, 3).long()\n",
        "    input = (all_triplets, dummy)\n",
        "    if kwargs.get('gnn'):\n",
        "      indcs = torch.ones(self.training.shape[0], dtype=torch.bool)\n",
        "      indcs[i] = False\n",
        "      input = Data(\n",
        "            x=data.x,\n",
        "            edge_index=data.edge_index,\n",
        "            edge_type=data.edge_type,\n",
        "            positive=all_triplets,\n",
        "            negative=dummy\n",
        "        )\n",
        "      \n",
        "    scoring_function.eval()\n",
        "    with torch.no_grad():\n",
        "      scores = scoring_function(input)[0]\n",
        "    fitness = F.softmax(scores, -1)\n",
        "    if head_or_tail == 'head':\n",
        "      self.head_cache[r][t] = all_entities.reshape(-1)[fitness.multinomial(num_samples=self.cache_size, replacement=False)]\n",
        "    elif head_or_tail == 'tail':\n",
        "      self.tail_cache[h][r] = all_entities.reshape(-1)[fitness.multinomial(num_samples=self.cache_size, replacement=False)]\n",
        "\n",
        "  def update_caches(self, batch, scoring_function, **kwargs):\n",
        "    self._update_cache(batch, scoring_function, 'head', **kwargs)\n",
        "    self._update_cache(batch, scoring_function, 'tail', **kwargs)\n",
        "\n",
        "  def train(self, model: Module, data, optimizer: torch.optim, loss_fn, update_cache=False) -> tuple((torch.float, torch.Tensor, torch.Tensor)):\n",
        "    optimizer.zero_grad()\n",
        "    model.train()\n",
        "\n",
        "    positive, negative = model(data) # forward pass\n",
        "\n",
        "    loss = loss_fn(positive, negative, torch.ones(1).to(self.device)) # margin ranking loss\n",
        "\n",
        "    loss.backward() # back propagation\n",
        "    optimizer.step() # parameter updates\n",
        "    if update_cache:\n",
        "      self.update_caches(data, model, gnn=True)\n",
        "    return loss.item()\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def _ranks(self, model, batch):\n",
        "    batch_size = batch.shape[0]\n",
        "\n",
        "    head_relation = batch[:, (0, 1)].repeat(self.candidates.shape[0], 1)\n",
        "    relation_tail = batch[:, (1, 2)].repeat(self.candidates.shape[0], 1)\n",
        "\n",
        "    entities = self.candidates.reshape(-1, 1).repeat(batch_size, 1)\n",
        "    entities = torch.cat(torch.split(entities, self.candidates.shape[0]), -1).reshape(-1, 1)\n",
        "\n",
        "    corrupted_head_triplets = torch.cat(\n",
        "        (entities, relation_tail), \n",
        "        -1\n",
        "    )\n",
        "    corrupted_tail_triplets = torch.cat(\n",
        "        (head_relation, entities), \n",
        "        -1\n",
        "    )\n",
        "    corrupted_head_triplets = torch.cat(torch.split(corrupted_head_triplets, batch_size), -1).reshape(batch_size, -1, 3)\n",
        "    corrupted_tail_triplets = torch.cat(torch.split(corrupted_tail_triplets, batch_size), -1).reshape(batch_size, -1, 3)\n",
        "\n",
        "    heads = batch[:, 0]\n",
        "    tails = batch[:, 2]\n",
        "\n",
        "    dummy = torch.ones(1, 3).long().to(self.device)\n",
        "\n",
        "    model.eval()\n",
        "    head_scores = model(\n",
        "        (dummy, corrupted_head_triplets.reshape(-1, 3))\n",
        "    )[1].reshape(batch_size, -1)\n",
        "    head_ranks = (head_scores.gather(dim=1, index=heads.reshape(-1, 1)) <= head_scores).sum(-1) # Max Policy\n",
        "\n",
        "    tail_scores = model(\n",
        "        (dummy, corrupted_tail_triplets.reshape(-1, 3))\n",
        "    )[1].reshape(batch_size, -1)\n",
        "    tail_ranks = (tail_scores.gather(dim=1, index=tails.reshape(-1, 1)) <= tail_scores).sum(-1)\n",
        "\n",
        "    return head_ranks.reshape(-1), tail_ranks.reshape(-1)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def MRR(self, model, set_type, batch_size, use_tqdm=False):\n",
        "    if set_type == 'validation':\n",
        "      eval_set = self.validation\n",
        "    elif set_type == 'testing':\n",
        "      eval_set = self.testing\n",
        "    else:\n",
        "      raise ValueError('Wrong data split specified.')\n",
        "    \n",
        "    sum = 0\n",
        "    size = 0\n",
        "    wrapper = tqdm if use_tqdm else (lambda z: z)\n",
        "    for batch in wrapper(torch.split(eval_set, batch_size)):\n",
        "      head_ranks, tail_ranks = self._ranks(model, batch)\n",
        "      sum += (1 / head_ranks).sum() + (1 / tail_ranks).sum()\n",
        "      size += head_ranks.shape[0] + tail_ranks.shape[0]\n",
        "    return sum / size\n",
        "      "
      ],
      "metadata": {
        "id": "jkiv69KokYfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn = GNN(dataset.num_entities, dataset.num_relations, 32, (32, 32, 32), 0.4)\n",
        "optimizer = Adam(gnn.parameters())\n",
        "margin = 1\n",
        "criterion = MarginRankingLoss(margin)"
      ],
      "metadata": {
        "id": "y-vQCEkSsmbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one(model, data, criterion, optimizer):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  p, n = model(data)\n",
        "  loss = criterion(p, n, torch.ones(1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss.item()"
      ],
      "metadata": {
        "id": "gZfl9l98rC2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cache_size = 10\n",
        "# head_cache = torch.rand(cache_size) * entities.shape[0]\n",
        "head_cache = (torch.rand(dataset.num_relations, entities.shape[0], cache_size) * entities.shape[0] - 1).round().long()\n",
        "tail_cache = (torch.rand(entities.shape[0], dataset.num_relations, cache_size) * entities.shape[0] - 1).round().long()\n",
        "\n",
        "# train_set\n",
        "# h, r, t = triplet\n"
      ],
      "metadata": {
        "id": "dP4xujppu6qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try:\n",
        "#   for triplet in tqdm(train_set):\n",
        "#     h, r, t = triplet\n",
        "#     index = torch.round(torch.rand(1) * cache_size - 1).long()\n",
        "#     h_bar = head_cache[r][t][index]\n",
        "#     index = torch.round(torch.rand(1) * cache_size - 1).long()\n",
        "#     t_bar = tail_cache[h][r][index]\n",
        "#     if torch.rand(1) < 0.5:\n",
        "#       negative_triplet = torch.tensor([h_bar, r, t]).reshape(1, 3)\n",
        "#     else:\n",
        "#       negative_triplet = torch.tensor([h, r, t_bar]).reshape(1, 3)\n",
        "# except KeyboardInterrupt:\n",
        "#   pass\n",
        "h, r, t = triplet\n",
        "head_or_tail = 'tail'\n",
        "i = 0\n",
        "replacement_size = 10\n",
        "\n",
        "new_candidates = torch.round(torch.rand(replacement_size) * (entities.shape[0] - 1)).long()\n",
        "if head_or_tail == 'head':\n",
        "  all_entities = torch.cat((head_cache[r][t], new_candidates)).reshape(-1, 1)\n",
        "elif head_or_tail == 'tail':\n",
        "  all_entities = torch.cat((tail_cache[h][r], new_candidates)).reshape(-1, 1)\n",
        "if head_or_tail == 'head':\n",
        "  partial = torch.tensor([r, t]).reshape(1, 2).repeat(cache_size + replacement_size, 1)\n",
        "  all_triplets = torch.cat((all_entities, partial), -1)\n",
        "elif head_or_tail == 'tail':\n",
        "  partial = torch.tensor([h, r]).reshape(1, 2).repeat(cache_size + replacement_size, 1)\n",
        "  all_triplets = torch.cat((partial, all_entities), -1)\n",
        "dummy = torch.ones(1, 3).long()\n",
        "input = (all_triplets, dummy)\n",
        "kwargs = {}\n",
        "if True or kwargs.get('gnn'):\n",
        "  indcs = torch.ones(train_set.shape[0], dtype=torch.bool)\n",
        "  indcs[i] = False\n",
        "  input = Data(\n",
        "        x=entities,\n",
        "        edge_index=train_set[indcs][:, (0, 2)].t().contiguous(),\n",
        "        edge_type=train_set[indcs][:, 1].t().contiguous(),\n",
        "        positive=all_triplets,\n",
        "        negative=dummy\n",
        "    )\n",
        "  \n",
        "gnn.eval()\n",
        "with torch.no_grad():\n",
        "  scores = gnn(input)[0]\n",
        "fitness = F.softmax(scores, -1)\n",
        "if head_or_tail == 'head':\n",
        "  head_cache[r][t] = all_entities.reshape(-1)[fitness.multinomial(num_samples=cache_size, replacement=False)]\n",
        "elif head_or_tail == 'tail':\n",
        "  tail_cache[h][r] = all_entities.reshape(-1)[fitness.multinomial(num_samples=cache_size, replacement=False)]"
      ],
      "metadata": {
        "id": "xwY0JusewGEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGWR4cy35fdV",
        "outputId": "51deed8d-0ee9-43bb-e2f2-edda667b8a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  for i, triplet in tqdm(enumerate(train_set)):\n",
        "    okay = False\n",
        "    while not okay:\n",
        "      h, r, t = triplet\n",
        "      index = torch.round(torch.rand(1) * (entities.shape[0] * 2)).long()\n",
        "      if index < entities.shape[0]:\n",
        "        # corrupt head\n",
        "        negative_triplet = torch.tensor([entities[index], r, t]).reshape(1, 3)\n",
        "      else:\n",
        "        # corrupt tail\n",
        "        index -= entities.shape[0]\n",
        "        negative_triplet = torch.tensor([h, r, entities[index]])\n",
        "      # okay = not ((negative_triplet == train_set).sum(-1) == 3).sum()\n",
        "      okay = True\n",
        "\n",
        "    indcs = torch.ones(train_set.shape[0], dtype=torch.bool)\n",
        "    indcs[i] = False\n",
        "    train_data = Data(\n",
        "        x=entities,\n",
        "        edge_index=train_set[indcs][:, (0, 2)].t().contiguous(),\n",
        "        edge_type=train_set[indcs][:, 1].t().contiguous(),\n",
        "        positive=triplet.reshape(1, 3),\n",
        "        negative=negative_triplet.reshape(1, 3)\n",
        "    )\n",
        "    print(train_one(gnn, train_data, criterion, optimizer))\n",
        "    # break\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oJ6cJcjknUJ",
        "outputId": "03bf8a4a-dbed-467f-9709-cac26ff0805a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:13, 13.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:25, 12.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4341979026794434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:38, 12.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.070107460021973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:39, 13.27s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MarginRankingLoss()()"
      ],
      "metadata": {
        "id": "5kPA45AetGzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
      ],
      "metadata": {
        "id": "SG1fLGKFNO8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metric"
      ],
      "metadata": {
        "id": "3T3u_MuyCuDO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d87ZALUBYec9",
        "cellView": "form"
      },
      "source": [
        "#@title find_start_and_end_indcs() PRIVATE-FUNCTION { form-width: \"15%\" }\n",
        "def find_start_and_end_indcs(entity, relation, entity_type, kg_sorted):\n",
        "  up = kg_sorted.shape[0]\n",
        "  down = 0\n",
        "  indx = kg_sorted.shape[0] // 2\n",
        "  found = False\n",
        "  while up - down > 1:\n",
        "    if kg_sorted[indx][entity_type].item() == entity:\n",
        "      found = True\n",
        "      break \n",
        "    elif kg_sorted[indx][entity_type].item() >= entity: \n",
        "      up = indx\n",
        "      indx = (up + down) // 2\n",
        "    else:\n",
        "      down = indx \n",
        "      indx = (up + down) // 2\n",
        "  if not found:\n",
        "    return None\n",
        "  while 1:\n",
        "    indx += 1\n",
        "    try:\n",
        "      if not kg_sorted[indx][entity_type].item() == entity:\n",
        "        indx -= 1\n",
        "        end_indx = indx\n",
        "        break\n",
        "    except:\n",
        "      end_indx = indx - 1\n",
        "      break\n",
        "  \n",
        "\n",
        "  while 1:\n",
        "    indx -= 1\n",
        "    try:\n",
        "      if not kg_sorted[indx][entity_type].item() == entity:\n",
        "        indx += 1\n",
        "        start_indx = indx\n",
        "        break\n",
        "    except:\n",
        "      start_indx = indx + 1\n",
        "      break\n",
        "  indcs = torch.arange(start_indx, end_indx + 1)\n",
        "  tns = kg_sorted[indcs]\n",
        "  srt_indcs = torch.sort(tns[:, 1])[1]\n",
        "\n",
        "  msk = tns[srt_indcs][:, 1] == relation\n",
        "  okay_indcs = torch.nonzero(msk).reshape(-1)\n",
        "  return indcs[srt_indcs[okay_indcs]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYPeOqPxkFtD"
      },
      "source": [
        "#@title get_psuedo_negative_entities() FUNCTIONS { form-width: \"15%\" }\n",
        "def get_psuedo_negative_entities(entity, relation, corrupt_at, kg_sorted):\n",
        "  if corrupt_at == Global.HEAD_INDEX.value:\n",
        "    entity_type = Global.TAIL_INDEX.value \n",
        "  elif corrupt_at == Global.TAIL_INDEX.value:\n",
        "    entity_type = Global.HEAD_INDEX.value\n",
        "\n",
        "  indcs = find_start_and_end_indcs(entity, relation, entity_type, kg_sorted=kg_sorted)\n",
        "  \n",
        "  if indcs is not None:\n",
        "    fact_triplets_entities = kg_sorted[indcs][:, corrupt_at]\n",
        "    features_copy = features.detach().clone()\n",
        "    features_copy[fact_triplets_entities] = -1\n",
        "    non_negative_mask = features_copy >= 0\n",
        "    ret = torch.nonzero(non_negative_mask).reshape(-1)\n",
        "    return ret\n",
        "  else:\n",
        "    return features.to(Global.DEVICE.value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcSjKWmGyYuj"
      },
      "source": [
        "#@title evaluation_rank() PRIVATE-FUNCTION { form-width: \"10%\" }\n",
        "@torch.no_grad()\n",
        "def evaluation_rank(model, eval_set, messaging_set):\n",
        "  h_pred_top10 = list()\n",
        "  t_pred_top10 = list()\n",
        "\n",
        "  for eval_triplet in tqdm(eval_set):\n",
        "    #use tqdm\n",
        "    head = eval_triplet[Global.HEAD_INDEX.value].item()\n",
        "    relation = eval_triplet[Global.RELATION_INDEX.value].item()\n",
        "    tail = eval_triplet[Global.TAIL_INDEX.value].item()\n",
        "\n",
        "    corrupted_tails = get_psuedo_negative_entities(\n",
        "        entity=head, \n",
        "        corrupt_at=Global.TAIL_INDEX.value, \n",
        "        kg_sorted=kg_sorted_heads\n",
        "    )\n",
        "    \n",
        "    num_psuedo_negative_triples = corrupted_tails.shape[0]\n",
        "    psuedo_negative_triplets_corrupted_tail = torch.vstack(\n",
        "        (\n",
        "            torch.ones(num_psuedo_negative_triples).to(Global.DEVICE.value).type(torch.long) * head,\n",
        "            torch.ones(num_psuedo_negative_triples).to(Global.DEVICE.value).type(torch.long) * relation,\n",
        "            corrupted_tails\n",
        "        )\n",
        "    ).t().to(Global.DEVICE.value)\n",
        "\n",
        "    corrupted_heads = get_psuedo_negative_entities(\n",
        "        entity=tail, \n",
        "        corrupt_at=Global.HEAD_INDEX.value, \n",
        "        kg_sorted=kg_sorted_tails\n",
        "    )\n",
        "\n",
        "    num_psuedo_negative_triples = corrupted_heads.shape[0]\n",
        "    psuedo_negative_triplets_corrupted_head = torch.vstack(\n",
        "        (\n",
        "            corrupted_heads,\n",
        "            torch.ones(num_psuedo_negative_triples).to(Global.DEVICE.value).type(torch.long) * relation,\n",
        "            torch.ones(num_psuedo_negative_triples).to(Global.DEVICE.value).type(torch.long) * tail\n",
        "        )\n",
        "    ).t().to(Global.DEVICE.value)\n",
        "\n",
        "    # eval_triplet: (h, r, t)\n",
        "    # psuedo_negative_triplets_head: (h′, r, t) for all h′\n",
        "    # psuedo_negative_triplets_tail: (h, r, t′) for all t′\n",
        "\n",
        "    # train_set being the messaging graph, calculate the score for (h, r, t)\n",
        "    # train_set being the messaging graph, calculate the scores for all (h′, r, t)\n",
        "    # train_set being the messaging graph, calculate the scores for all (h, r, t′)\n",
        "\n",
        "    graph_data_for_object_tail = graph_data_maker(\n",
        "      messaging=messaging_set,\n",
        "      supervision=eval_triplet.reshape(1, 3),\n",
        "      negative_samples=psuedo_negative_triplets_corrupted_tail,\n",
        "      x=features.to(Global.DEVICE.value),\n",
        "      x_feature='one-hot'\n",
        "    )\n",
        "\n",
        "    graph_data_for_object_head = graph_data_maker(\n",
        "            messaging=messaging_set,\n",
        "            supervision=eval_triplet.reshape(1, 3),\n",
        "            negative_samples=psuedo_negative_triplets_corrupted_head,\n",
        "            x=features.to(Global.DEVICE.value),\n",
        "            x_feature='one-hot'\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "    scores_for_object_tail = torch.cat(model(graph_data_for_object_tail))\n",
        "\n",
        "    sorted_by_scores_for_object_tail_indcs = torch.sort(scores_for_object_tail, descending=True)[1]\n",
        "\n",
        "    tail_objects = torch.cat((graph_data_for_object_tail.edge_index_supervision[1], graph_data_for_object_tail.edge_index_negative[1]))\n",
        "    top10_tails = tail_objects[sorted_by_scores_for_object_tail_indcs[:10]]\n",
        "    t_pred_top10.append(top10_heads)\n",
        "\n",
        "    model.eval()\n",
        "    scores_for_object_head = torch.cat(model(graph_data_for_object_head))\n",
        "\n",
        "    sorted_by_scores_for_object_head_indcs = torch.sort(scores_for_object_head, descending=True)[1]\n",
        "\n",
        "    head_objects = torch.cat((graph_data_for_object_head.edge_index_supervision[0], graph_data_for_object_head.edge_index_negative[0]))\n",
        "    top10_heads = head_objects[sorted_by_scores_for_object_head_indcs[:10]]\n",
        "    h_pred_top10.append(top10_tails)\n",
        "\n",
        "    # print('')\n",
        "    ############################################################################## 1\n",
        "    # if False:\n",
        "    #   hit_index = (\n",
        "    #             tail_objects[sorted_by_scores_for_object_head_indcs[:500]] == eval_triplet[2]\n",
        "    #           ).nonzero(as_tuple=True)[0] + 1\n",
        "    #   if hit_index.shape[0]:\n",
        "    #     print(f'Tail ranked at {hit_index.item()}')\n",
        "    #     print('-' * 30)\n",
        "    # ############################################################################### 2\n",
        "\n",
        "    # ############################################################################### 3\n",
        "    # hit_index = (\n",
        "    #             head_objects[sorted_by_scores_for_object_tail_indcs[:500]] == eval_triplet[0]\n",
        "    #           ).nonzero(as_tuple=True)[0] + 1\n",
        "    # if hit_index.shape[0]:\n",
        "    #   print(f'Head ranked at {hit_index.item()}')\n",
        "    #   print('-' * 30)\n",
        "    ############################################################################## 4\n",
        "    \n",
        "  model.train()\n",
        "  return torch.stack(h_pred_top10), torch.stack(t_pred_top10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzR8BWA0N628"
      },
      "source": [
        "#@title evaluate_hits_at_10(model, mode) FUNCTION{ form-width: \"15%\" }\n",
        "def evaluate_hits_at_10(model: GNN, mode:str) -> torch.float:\n",
        "  if mode == 'validation':\n",
        "    head_objects_top10, tail_objects_top10 = evaluation_rank(model, val_set, train_set)\n",
        "    return evaluator.eval(\n",
        "            head_objects_top10,\n",
        "            tail_objects_top10,\n",
        "            val_set,\n",
        "            False\n",
        "    )\n",
        "  elif mode == 'testing':\n",
        "    head_objects_top10, tail_objects_top10 = evaluation_rank(model, test_set, torch.cat((train_set, val_set), dim=0))\n",
        "    return evaluator.eval(\n",
        "            head_objects_top10,\n",
        "            tail_objects_top10,\n",
        "            test_set,\n",
        "            False\n",
        "          )\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}